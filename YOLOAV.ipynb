{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Presentation Link: https://hcpss-my.sharepoint.com/:p:/g/personal/tcarte6482_inst_hcpss_org/EaypnPAeNSlAupVA95ZEl64BHHoIF1MtkDF6yXVWWNcysQ?e=NueUfT"
      ],
      "metadata": {
        "id": "bEnicqyeke3e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFrFMnMxFLv7"
      },
      "source": [
        "#Visualizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rfdRT31uNxE3"
      },
      "outputs": [],
      "source": [
        "!pip install utm\n",
        "!pip install geopy\n",
        "!pip install pcl\n",
        "!python --version\n",
        "!pip install open3d\n",
        "!pip install pyntcloud\n",
        "#!pip install pcl.pcl_visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2bU7wXzlsEQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "import math\n",
        "import utm\n",
        "import geopy.distance\n",
        "from geopy.distance import geodesic\n",
        "import cv2\n",
        "import yaml\n",
        "import json\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "#import pcl\n",
        "#import pcl.pcl_visualization\n",
        "import json\n",
        "\n",
        "from sklearn.neighbors import KDTree\n",
        "import open3d as o3d\n",
        "from pyntcloud import PyntCloud\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH1kllAjN5Cy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv0bM3YI0EoK"
      },
      "outputs": [],
      "source": [
        "dataset_route_stats = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cadc_dataset_route_stats.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HKYFsx7cDIyt"
      },
      "outputs": [],
      "source": [
        "dataset_route_stats.head(75)\n",
        "#dataset_route_stats['Dataset Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBOz3xorEjUD"
      },
      "outputs": [],
      "source": [
        "def convert_novatel_to_pose(novatel):\n",
        "  poses = [];\n",
        "  FIRST_RUN = True;\n",
        "  origin = [];\n",
        "\n",
        "  for gps_msg in novatel:\n",
        "    # utm_data[0] = East (m), utm_data[1] = North (m)\n",
        "    utm_data = utm.from_latlon(float(gps_msg[0]), float(gps_msg[1]));\n",
        "    # Ellipsoidal height = MSL (orthometric) + undulation\n",
        "    ellipsoidal_height = float(gps_msg[2]) + float(gps_msg[3]);\n",
        "\n",
        "    roll = np.deg2rad(float(gps_msg[7]));\n",
        "    pitch = np.deg2rad(float(gps_msg[8]));\n",
        "\n",
        "    # Azimuth = north at 0 degrees, east at 90 degrees, south at 180 degrees and west at 270 degrees\n",
        "    azimuth = float(gps_msg[9]);\n",
        "    # yaw = north at 0 deg, 90 at west and 180 at south, east at 270 deg\n",
        "    yaw = np.deg2rad(-1.0 * azimuth);\n",
        "\n",
        "    c_phi = math.cos(roll);\n",
        "    s_phi = math.sin(roll);\n",
        "    c_theta = math.cos(pitch);\n",
        "    s_theta = math.sin(pitch);\n",
        "    c_psi = math.cos(yaw);\n",
        "    s_psi = math.sin(yaw);\n",
        "\n",
        "    if FIRST_RUN:\n",
        "      origin = [utm_data[0], utm_data[1], ellipsoidal_height];\n",
        "      FIRST_RUN = False;\n",
        "\n",
        "    # This is the T_locallevel_body transform where ENU is the local level frame\n",
        "    # and the imu is the body frame\n",
        "    # https://www.novatel.com/assets/Documents/Bulletins/apn037.pdf\n",
        "    poses.append(np.matrix([\n",
        "      [c_psi * c_phi - s_psi * s_theta * s_phi, -s_psi * c_theta, c_psi * s_phi + s_psi * s_theta * c_phi, utm_data[0] - origin[0]],\n",
        "      [s_psi * c_phi + c_psi * s_theta * s_phi, c_psi * c_theta, s_psi * s_phi - c_psi * s_theta * c_phi, utm_data[1] - origin[1]],\n",
        "      [-c_theta * s_phi, s_theta, c_theta * c_phi, ellipsoidal_height - origin[2]],\n",
        "      [0.0, 0.0, 0.0, 1.0]]));\n",
        "\n",
        "  return poses;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FehquDtVmguC"
      },
      "outputs": [],
      "source": [
        "def load_calibration(calib_path):\n",
        "  calib = {}\n",
        "\n",
        "  # Get calibrations\n",
        "  calib['extrinsics'] = yaml.load(open(calib_path + '/extrinsics.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM00'] = yaml.load(open(calib_path + '/00.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM01'] = yaml.load(open(calib_path + '/01.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM02'] = yaml.load(open(calib_path + '/02.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM03'] = yaml.load(open(calib_path + '/03.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM04'] = yaml.load(open(calib_path + '/04.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM05'] = yaml.load(open(calib_path + '/05.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM06'] = yaml.load(open(calib_path + '/06.yaml'), yaml.SafeLoader)\n",
        "  calib['CAM07'] = yaml.load(open(calib_path + '/07.yaml'), yaml.SafeLoader)\n",
        "\n",
        "  return calib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s34VnmUSmqWn"
      },
      "outputs": [],
      "source": [
        "def load_novatel_data(novatel_path):\n",
        "  files = os.listdir(novatel_path);\n",
        "  novatel = [];\n",
        "\n",
        "  for file in sorted(files):\n",
        "    with open(novatel_path + file) as fp:\n",
        "      novatel.append(fp.readline().split(' '));\n",
        "\n",
        "  return novatel;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8fusPd9mPZe"
      },
      "outputs": [],
      "source": [
        "class lidar_utils:\n",
        "  def __init__(self, T_CAM_LIDAR):\n",
        "    self.T_CAM_LIDAR = T_CAM_LIDAR;\n",
        "    print(\"init lidar utils\")\n",
        "\n",
        "  def project_points(self, img, lidar_path, T_IMG_CAM, T_CAM_LIDAR, dist_coeffs, DISTORTED):\n",
        "    self.T_CAM_LIDAR = T_CAM_LIDAR;\n",
        "\n",
        "    scan_data = np.fromfile(lidar_path, dtype=np.float32);\n",
        "\n",
        "    # 2D array where each row contains a point [x, y, z, intensity]\n",
        "    lidar = scan_data.reshape((-1, 4));\n",
        "\n",
        "    # Get height and width of the image\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    projected_points = [];\n",
        "\n",
        "    [rows, cols] = lidar.shape;\n",
        "    # print(lidar[0,:])\n",
        "    # print(lidar[1,:])\n",
        "    # print(lidar[1,0:3])\n",
        "\n",
        "    for i in range(rows):\n",
        "      # print(lidar[i,:])\n",
        "      p = np.array([0.0, 0.0, 0.0, 1.0]);\n",
        "      p[0:3] = lidar[i,0:3];\n",
        "      # print(\"p\",p);\n",
        "      projected_p =  np.matmul(self.T_CAM_LIDAR, p.transpose());\n",
        "      if projected_p[2] < 2: # arbitrary cut off\n",
        "        continue;\n",
        "      projected_points.append([projected_p[0], projected_p[1], projected_p[2]]);\n",
        "\n",
        "    #print(\"projected_points\", projected_points)\n",
        "\n",
        "    # Send [x, y, z] and Transform\n",
        "    projected_points_np = np.array(projected_points)\n",
        "    image_points = self.project(projected_points_np, T_IMG_CAM, dist_coeffs, DISTORTED);\n",
        "    # print(\"image_points\")\n",
        "    # print(image_points)\n",
        "\n",
        "    radius = 0\n",
        "\n",
        "    [rows, cols] = projected_points_np.shape;\n",
        "\n",
        "    NUM_COLOURS = 7;\n",
        "    rainbow = [\n",
        "      [0, 0, 255], # Red\n",
        "      [0, 127, 255], # Orange\n",
        "      [0, 255, 255], # Yellow\n",
        "      [0, 255, 0], # Green\n",
        "      [255, 0, 0], # Blue\n",
        "      [130, 0, 75], # Indigo\n",
        "      [211, 0, 148] # Violet\n",
        "    ];\n",
        "\n",
        "    for i in range(rows):\n",
        "      colour = int(NUM_COLOURS*(projected_points_np[i][2]/70));\n",
        "      x = int(image_points[i][0])\n",
        "      y = int(image_points[i][1])\n",
        "      if x < 0 or x > w - 1 or y < 0 or y > h - 1:\n",
        "        continue;\n",
        "      if colour > NUM_COLOURS-1:\n",
        "        continue;\n",
        "\n",
        "      cv2.circle(img, (x,y), radius, rainbow[colour], thickness=2, lineType=8, shift=0);\n",
        "\n",
        "    return img;\n",
        "\n",
        "  def project(self, p_in, T_IMG_CAM, dist_coeffs, DISTORTED):\n",
        "    p_out = []\n",
        "    [rows, cols] = p_in.shape;\n",
        "\n",
        "    for i in range(rows):\n",
        "      # print(\"p_in[i]\", p_in[i])\n",
        "      point = np.array([0.0, 0.0, 0.0, 1.0]);\n",
        "      # print(\"p_in[i][0]\",p_in[i][0])\n",
        "      point[0:3] = p_in[i];\n",
        "      # print(\"p[0]\",p[0])\n",
        "      if DISTORTED:\n",
        "        rvec = tvec = np.zeros(3)\n",
        "        # print(p[0:3])\n",
        "        # print(T_IMG_CAM[0:3,0:3])\n",
        "        # print(np.array(calib['CAM02']['distortion_coefficients']['data']))\n",
        "        image_points, jac = cv2.projectPoints(np.array([point[0:3]]), rvec, tvec, T_IMG_CAM[0:3,0:3], dist_coeffs)\n",
        "        p_out.append([image_points[0,0,0], image_points[0,0,1]]);\n",
        "        # print(\"image_points\", image_points[0,0])\n",
        "      else:\n",
        "        curr = np.matmul(T_IMG_CAM, point.transpose()).transpose();\n",
        "        # print(\"curr\",curr);\n",
        "        done = [curr[0] / curr[2], curr[1] / curr[2]]\n",
        "        p_out.append(done);\n",
        "        # print(\"p_out append\", done)\n",
        "\n",
        "    return p_out;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMMSp0ycp_Hx"
      },
      "outputs": [],
      "source": [
        "def run_demo_vehicle_path():\n",
        "  #novatel_path = '/media/matthew/WAVELAB_2TB/winter/data/0027/processed/novatel/data/';\n",
        "  novatel_path = '/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/0001/labeled/novatel/data/'\n",
        "  novatel = load_novatel_data(novatel_path);\n",
        "  poses = convert_novatel_to_pose(novatel);\n",
        "\n",
        "  mpl.rcParams['legend.fontsize'] = 10\n",
        "\n",
        "  fig = plt.figure()\n",
        "  #ax = fig.gca(111, projection = '3d')\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "\n",
        "  ax.set_title('Vehicle path')\n",
        "  ax.set_xlabel('East (m)')\n",
        "  ax.set_ylabel('North (m)')\n",
        "  ax.set_zlabel('Up (m)')\n",
        "\n",
        "  length = 1\n",
        "  A = np.matrix([[0, 0, 0, 1],\n",
        "                [length, 0, 0, 1],\n",
        "                [0, 0, 0, 1],\n",
        "                [0, length, 0, 1],\n",
        "                [0, 0, 0, 1],\n",
        "                [0, 0, length, 1]]).transpose();\n",
        "\n",
        "  for pose in poses:\n",
        "    B = np.matmul(pose, A);\n",
        "    ax.plot([B[0,0], B[0,1]], [B[1,0], B[1,1]],[B[2,0],B[2,1]], 'r-'); # x: red\n",
        "    ax.plot([B[0,2], B[0,3]], [B[1,2], B[1,3]],[B[2,2],B[2,3]], 'g-'); # y: green\n",
        "    ax.plot([B[0,4], B[0,5]], [B[1,4], B[1,5]],[B[2,4],B[2,5]], 'b-'); # z: blue\n",
        "\n",
        "  # Equal axis doesn't seem to work so set an arbitrary limit to the z axis\n",
        "  ax.set_zlim3d(-10,10)\n",
        "\n",
        "  plt.show()\n",
        "run_demo_vehicle_path()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyhB3FH7pQMI"
      },
      "outputs": [],
      "source": [
        "def run_demo_tracklets():\n",
        "  frame = 26\n",
        "  cam = '0'\n",
        "  seq = '0010'\n",
        "  DISTORTED = False\n",
        "  MOVE_FORWARD = False\n",
        "  # BASE = \"/media/matthew/WAVELAB_2TB/winter/data/\"\n",
        "  #BASE = \"/media/matthew/MOOSE-4TB/2019_02_27/\"\n",
        "  #CALIB_BASE = \"/media/matthew/WAVELAB_2TB/winter/\"\n",
        "  BASE = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\"\n",
        "  CALIB_BASE = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\"\n",
        "\n",
        "  if DISTORTED:\n",
        "    path_type = 'raw'\n",
        "  else:\n",
        "    path_type = 'processed'\n",
        "  path_type = 'labeled'\n",
        "\n",
        "  lidar_path = BASE + seq + \"/\" + path_type + \"/lidar_points/data/\" + format(frame, '010') + \".bin\";\n",
        "  calib_path = CALIB_BASE + \"calib\";\n",
        "  img_path = BASE + seq + \"/\" + path_type + \"/image_0\" + cam + \"/data/\" + format(frame, '010') + \".png\";\n",
        "\n",
        "\n",
        "\n",
        "  annotations_file = BASE + seq + \"/3d_ann.json\";\n",
        "\n",
        "  # Load 3d annotations\n",
        "  annotations_data = None\n",
        "  with open(annotations_file) as f:\n",
        "      annotations_data = json.load(f)\n",
        "\n",
        "  calib = load_calibration(calib_path);\n",
        "\n",
        "  # Projection matrix from camera to image frame\n",
        "  T_IMG_CAM = np.eye(4);\n",
        "  T_IMG_CAM[0:3,0:3] = np.array(calib['CAM0' + cam]['camera_matrix']['data']).reshape(-1, 3);\n",
        "  T_IMG_CAM = T_IMG_CAM[0:3,0:4]; # remove last row\n",
        "\n",
        "  T_CAM_LIDAR = np.linalg.inv(np.array(calib['extrinsics']['T_LIDAR_CAM0' + cam]));\n",
        "\n",
        "  T_IMG_LIDAR = np.matmul(T_IMG_CAM, T_CAM_LIDAR);\n",
        "\n",
        "  img = cv2.imread(img_path)\n",
        "  img_h, img_w = img.shape[:2]\n",
        "\n",
        "  # Add each cuboid to image\n",
        "  for cuboid in annotations_data[frame]['cuboids']:\n",
        "    T_Lidar_Cuboid = np.eye(4);\n",
        "    T_Lidar_Cuboid[0:3,0:3] = R.from_euler('z', cuboid['yaw'], degrees=False).as_matrix();\n",
        "    T_Lidar_Cuboid[0][3] = cuboid['position']['x'];\n",
        "    T_Lidar_Cuboid[1][3] = cuboid['position']['y'];\n",
        "    T_Lidar_Cuboid[2][3] = cuboid['position']['z'];\n",
        "\n",
        "    #T_Lidar_Cuboid[0][3] = -T_Lidar_Cuboid[0][3];\n",
        "\n",
        "    # if (cuboid['label'] != 'Truck'):\n",
        "    #   continue;\n",
        "    # if (cuboid['attributes']['truck_type'] != 'Semi_Truck'):\n",
        "    #   continue;\n",
        "    # print(cuboid['yaw'])\n",
        "    # print(cuboid)\n",
        "    # print(T_Lidar_Cuboid)\n",
        "    width = cuboid['dimensions']['x'];\n",
        "    length = cuboid['dimensions']['y'];\n",
        "    height = cuboid['dimensions']['z'];\n",
        "    radius = 3\n",
        "\n",
        "    # Create circle in middle of the cuboid\n",
        "    tmp = np.matmul(T_CAM_LIDAR, T_Lidar_Cuboid);\n",
        "    if tmp[2][3] < 0: # Behind camera\n",
        "      continue;\n",
        "    test = np.matmul(T_IMG_CAM, tmp);\n",
        "    x = int(test[0][3]/test[2][3]);\n",
        "    y = int(test[1][3]/test[2][3]);\n",
        "    cv2.circle(img, (x,y), radius, [0, 0, 255], thickness=2, lineType=8, shift=0);\n",
        "\n",
        "    front_right_bottom = np.array([[1,0,0,length/2],[0,1,0,-width/2],[0,0,1,-height/2],[0,0,0,1]]);\n",
        "    front_right_top = np.array([[1,0,0,length/2],[0,1,0,-width/2],[0,0,1,height/2],[0,0,0,1]]);\n",
        "    front_left_bottom = np.array([[1,0,0,length/2],[0,1,0,width/2],[0,0,1,-height/2],[0,0,0,1]]);\n",
        "    front_left_top = np.array([[1,0,0,length/2],[0,1,0,width/2],[0,0,1,height/2],[0,0,0,1]]);\n",
        "\n",
        "    back_right_bottom = np.array([[1,0,0,-length/2],[0,1,0,-width/2],[0,0,1,-height/2],[0,0,0,1]]);\n",
        "    back_right_top = np.array([[1,0,0,-length/2],[0,1,0,-width/2],[0,0,1,height/2],[0,0,0,1]]);\n",
        "    back_left_bottom = np.array([[1,0,0,-length/2],[0,1,0,width/2],[0,0,1,-height/2],[0,0,0,1]]);\n",
        "    back_left_top = np.array([[1,0,0,-length/2],[0,1,0,width/2],[0,0,1,height/2],[0,0,0,1]]);\n",
        "\n",
        "    # Project to image\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, front_right_bottom));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    f_r_b = np.matmul(T_IMG_CAM, tmp);\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, front_right_top));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    f_r_t = np.matmul(T_IMG_CAM, tmp);\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, front_left_bottom));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    f_l_b = np.matmul(T_IMG_CAM, tmp);\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, front_left_top));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    f_l_t = np.matmul(T_IMG_CAM, tmp);\n",
        "\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, back_right_bottom));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    b_r_b = np.matmul(T_IMG_CAM, tmp);\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, back_right_top));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    b_r_t = np.matmul(T_IMG_CAM, tmp);\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, back_left_bottom));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    b_l_b = np.matmul(T_IMG_CAM, tmp);\n",
        "    tmp = np.matmul(T_CAM_LIDAR, np.matmul(T_Lidar_Cuboid, back_left_top));\n",
        "    if tmp[2][3] < 0:\n",
        "      continue;\n",
        "    b_l_t = np.matmul(T_IMG_CAM, tmp);\n",
        "\n",
        "    # Make sure the\n",
        "    # Remove z\n",
        "    f_r_b_coord = (int(f_r_b[0][3]/f_r_b[2][3]), int(f_r_b[1][3]/f_r_b[2][3]));\n",
        "    f_r_t_coord = (int(f_r_t[0][3]/f_r_t[2][3]), int(f_r_t[1][3]/f_r_t[2][3]));\n",
        "    f_l_b_coord = (int(f_l_b[0][3]/f_l_b[2][3]), int(f_l_b[1][3]/f_l_b[2][3]));\n",
        "    f_l_t_coord = (int(f_l_t[0][3]/f_l_t[2][3]), int(f_l_t[1][3]/f_l_t[2][3]));\n",
        "    if f_r_b_coord[0] < 0 or f_r_b_coord[0] > img_w or f_r_b_coord[1] < 0 or f_r_b_coord[1] > img_h:\n",
        "      continue;\n",
        "    if f_r_t_coord[0] < 0 or f_r_t_coord[0] > img_w or f_r_t_coord[1] < 0 or f_r_t_coord[1] > img_h:\n",
        "      continue;\n",
        "    if f_l_b_coord[0] < 0 or f_l_b_coord[0] > img_w or f_l_b_coord[1] < 0 or f_l_b_coord[1] > img_h:\n",
        "      continue;\n",
        "    if f_l_t_coord[0] < 0 or f_l_t_coord[0] > img_w or f_l_t_coord[1] < 0 or f_l_t_coord[1] > img_h:\n",
        "      continue;\n",
        "\n",
        "    b_r_b_coord = (int(b_r_b[0][3]/b_r_b[2][3]), int(b_r_b[1][3]/b_r_b[2][3]));\n",
        "    b_r_t_coord = (int(b_r_t[0][3]/b_r_t[2][3]), int(b_r_t[1][3]/b_r_t[2][3]));\n",
        "    b_l_b_coord = (int(b_l_b[0][3]/b_l_b[2][3]), int(b_l_b[1][3]/b_l_b[2][3]));\n",
        "    b_l_t_coord = (int(b_l_t[0][3]/b_l_t[2][3]), int(b_l_t[1][3]/b_l_t[2][3]));\n",
        "    if b_r_b_coord[0] < 0 or b_r_b_coord[0] > img_w or b_r_b_coord[1] < 0 or b_r_b_coord[1] > img_h:\n",
        "      continue;\n",
        "    if b_r_t_coord[0] < 0 or b_r_t_coord[0] > img_w or b_r_t_coord[1] < 0 or b_r_t_coord[1] > img_h:\n",
        "      continue;\n",
        "    if b_l_b_coord[0] < 0 or b_l_b_coord[0] > img_w or b_l_b_coord[1] < 0 or b_l_b_coord[1] > img_h:\n",
        "      continue;\n",
        "    if b_l_t_coord[0] < 0 or b_l_t_coord[0] > img_w or b_l_t_coord[1] < 0 or b_l_t_coord[1] > img_h:\n",
        "      continue;\n",
        "\n",
        "    # Draw  12 lines\n",
        "    # Front\n",
        "    cv2.line(img, f_r_b_coord, f_r_t_coord, [0, 0, 255], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, f_r_b_coord, f_l_b_coord, [0, 0, 255], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, f_l_b_coord, f_l_t_coord, [0, 0, 255], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, f_l_t_coord, f_r_t_coord, [0, 0, 255], thickness=2, lineType=8, shift=0);\n",
        "    # back\n",
        "    cv2.line(img, b_r_b_coord, b_r_t_coord, [0, 0, 100], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, b_r_b_coord, b_l_b_coord, [0, 0, 100], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, b_l_b_coord, b_l_t_coord, [0, 0, 100], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, b_l_t_coord, b_r_t_coord, [0, 0, 100], thickness=2, lineType=8, shift=0);\n",
        "    # connect front to back\n",
        "    cv2.line(img, f_r_b_coord, b_r_b_coord, [0, 0, 150], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, f_r_t_coord, b_r_t_coord, [0, 0, 150], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, f_l_b_coord, b_l_b_coord, [0, 0, 150], thickness=2, lineType=8, shift=0);\n",
        "    cv2.line(img, f_l_t_coord, b_l_t_coord, [0, 0, 150], thickness=2, lineType=8, shift=0);\n",
        "    #bunch of print statements I commented out lol\n",
        "    #print(cuboid)\n",
        "    #print(f_r_b_coord)\n",
        "    #print(f_r_t_coord)\n",
        "    #print(f_l_b_coord)\n",
        "    #print(f_l_t_coord)\n",
        "\n",
        "    #print(b_r_b_coord)\n",
        "    #print(b_r_t_coord)\n",
        "    #print(b_l_b_coord)\n",
        "    #print(b_l_t_coord)\n",
        "\n",
        "    #break;\n",
        "\n",
        "  cv2_imshow(img)\n",
        "  # cv2.imwrite(\"test.png\", img)\n",
        "  cv2.waitKey(10000)\n",
        "run_demo_tracklets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfzX_TvCzIfg"
      },
      "outputs": [],
      "source": [
        "def dror_filter(input_cloud):\n",
        "    radius_multiplier_ = 3\n",
        "    azimuth_angle_ = 0.16\n",
        "    min_neighbors_ = 3\n",
        "    k_neighbors_ = min_neighbors_ + 1\n",
        "    min_search_radius_ = 0.04\n",
        "\n",
        "    filtered_cloud_list = []\n",
        "\n",
        "    # Convert PyntCloud to NumPy array\n",
        "    points = input_cloud.points[['x', 'y', 'z']].to_numpy()\n",
        "\n",
        "    # Create KDTree for neighbor search\n",
        "    kd_tree = KDTree(points)\n",
        "\n",
        "    # Go over all the points and check which don't have enough neighbors\n",
        "    for p_id in range(points.shape[0]):\n",
        "        x_i = points[p_id, 0]\n",
        "        y_i = points[p_id, 1]\n",
        "        range_i = math.sqrt(x_i**2 + y_i**2)\n",
        "        search_radius_dynamic = radius_multiplier_ * azimuth_angle_ * math.pi / 180 * range_i\n",
        "\n",
        "        if search_radius_dynamic < min_search_radius_:\n",
        "            search_radius_dynamic = min_search_radius_\n",
        "\n",
        "        distances, indices = kd_tree.query_radius([points[p_id]], r=search_radius_dynamic, return_distance=True)\n",
        "        neighbors = len(indices[0]) - 1  # Subtract 1 to exclude the point itself\n",
        "\n",
        "        # This point is not snow, add it to the filtered_cloud_list\n",
        "        if neighbors >= min_neighbors_:\n",
        "            filtered_cloud_list.append(points[p_id])\n",
        "\n",
        "    filtered_cloud = np.array(filtered_cloud_list, dtype=np.float32)\n",
        "    return PyntCloud(pd.DataFrame(filtered_cloud, columns=['x', 'y', 'z']))\n",
        "\n",
        "def crop_cloud(input_cloud):\n",
        "    min_vals = np.array([-4, -4, -3])\n",
        "    max_vals = np.array([4, 4, 10])\n",
        "\n",
        "    # Filter points within the bounding box\n",
        "    mask = (\n",
        "        (input_cloud.points['x'] >= min_vals[0]) & (input_cloud.points['x'] <= max_vals[0]) &\n",
        "        (input_cloud.points['y'] >= min_vals[1]) & (input_cloud.points['y'] <= max_vals[1]) &\n",
        "        (input_cloud.points['z'] >= min_vals[2]) & (input_cloud.points['z'] <= max_vals[2])\n",
        "    )\n",
        "\n",
        "    cropped_points = input_cloud.points[mask]\n",
        "    return PyntCloud(cropped_points)\n",
        "\n",
        "def print_snow_points(frame):\n",
        "    seq = format(frame, '04')\n",
        "\n",
        "    annotations_file = BASE + seq + \"/3d_ann.json\"\n",
        "    export_annotations_file = BASE + seq + \"/3d_ann_p.json\"\n",
        "    path_type = \"labeled\"\n",
        "\n",
        "    # Load lidar data for this frame\n",
        "    lidar_path = BASE + seq + \"/\" + path_type + \"/lidar_points/data/\" + format(0, '010') + \".bin\"\n",
        "    scan_data = np.fromfile(lidar_path, dtype=np.float32)\n",
        "    lidar = scan_data.reshape((-1, 4))\n",
        "\n",
        "    # Convert lidar 2D array to PyntCloud\n",
        "    point_cloud = PyntCloud(pd.DataFrame(lidar[:, 0:3], columns=['x', 'y', 'z']))\n",
        "\n",
        "    # Crop the point cloud\n",
        "    cropped_cloud = crop_cloud(point_cloud)\n",
        "\n",
        "    # Run DROR filter\n",
        "    filtered_cloud = dror_filter(cropped_cloud)\n",
        "\n",
        "    # Print number of snow points\n",
        "    number_snow_points = len(cropped_cloud.points) - len(filtered_cloud.points)\n",
        "    print(number_snow_points)\n",
        "\n",
        "    # Visualization (PyntCloud visualization support is limited, might need to use an external tool like Open3D)\n",
        "    # Example using Open3D\n",
        "    import open3d as o3d\n",
        "\n",
        "    cropped_cloud_o3d = o3d.geometry.PointCloud()\n",
        "    cropped_cloud_o3d.points = o3d.utility.Vector3dVector(cropped_cloud.points[['x', 'y', 'z']].to_numpy())\n",
        "\n",
        "    o3d.visualization.draw_plotly([cropped_cloud_o3d])\n",
        "\n",
        "BASE = '/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/'\n",
        "LOOP = False\n",
        "\n",
        "print_snow_points(1) #sensor 1 of 3/6/18 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz1SUUjsGii1"
      },
      "outputs": [],
      "source": [
        "def bev(s1,s2,f1,f2,frame,cam):\n",
        "    '''\n",
        "\n",
        "    :param s1: example 15 (15 meter to the left of the car)\n",
        "    :param s2: s2 meters from the right of the car\n",
        "    :param f1: f1 meters from the front of the car\n",
        "    :param f2: f2 meters from the back of the car\n",
        "    :param frame: the frame number\n",
        "    :return:\n",
        "    '''\n",
        "    camNum = '0001/'\n",
        "    DISTORTED = False\n",
        "\n",
        "    if DISTORTED:\n",
        "        path_type = 'raw'\n",
        "    else:\n",
        "        path_type = 'processedmoose'\n",
        "    path_type = 'labeled' #according to my own file structure\n",
        "\n",
        "    #lidar_path = \"/media/wavelab/d3cd89ab-7705-4996-94f3-01da25ba8f50/autonomoose/\" + path_type + \"/lidar_points/data/\" + format(frame, '010') + \".bin\"\n",
        "    lidar_path = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\" + camNum + path_type + \"/lidar_points/data/\" + format(frame, '010') + \".bin\"\n",
        "    #limit the viewing range\n",
        "    side_range = [-s1,s2] #15 meters from either side of the car\n",
        "    fwd_range = [-f1,f2] # 15 m infront of the car\n",
        "\n",
        "    scan_data = np.fromfile(lidar_path, dtype= np.float32) #numpy from file reads binary file\n",
        "    #scan_data is a single row of all the lidar values\n",
        "    # 2D array where each row contains a point [x, y, z, intensity]\n",
        "    #we covert scan_data to format said above\n",
        "    lidar = scan_data.reshape((-1, 4));\n",
        "\n",
        "    lidar_x = lidar[:,0]\n",
        "    lidar_y = lidar[:,1]\n",
        "    lidar_z = lidar [:,2]\n",
        "\n",
        "\n",
        "\n",
        "    lidar_x_trunc = []\n",
        "    lidar_y_trunc = []\n",
        "    lidar_z_trunc = []\n",
        "\n",
        "    for i in range(len(lidar_x)):\n",
        "        if lidar_x[i] > fwd_range[0] and lidar_x[i] < fwd_range[1]: #get the lidar coordinates\n",
        "            if lidar_y[i] > side_range[0] and lidar_y[i] < side_range[1]:\n",
        "\n",
        "                lidar_x_trunc.append(lidar_x[i])\n",
        "                lidar_y_trunc.append(lidar_y[i])\n",
        "                lidar_z_trunc.append(lidar_z[i])\n",
        "\n",
        "    # to use for the plot\n",
        "    x_img = [i* -1 for i in lidar_y_trunc] #in the image plot, the negative lidar y axis is the img x axis\n",
        "    y_img = lidar_x_trunc #the lidar x axis is the img y axis\n",
        "    pixel_values = lidar_z_trunc\n",
        "\n",
        "\n",
        "    #shift values such that 0,0 is the minimum\n",
        "    x_img = [i -side_range[0] for i in x_img]\n",
        "    y_img = [i -fwd_range[0] for i in y_img]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    tracklets\n",
        "    '''\n",
        "\n",
        "\n",
        "    #annotations_file = '/media/wavelab/d3cd89ab-7705-4996-94f3-01da25ba8f50/autonomoose/3d_annotations.json';\n",
        "    annotations_file = '/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/' + camNum + '3d_ann.json'\n",
        "    # Load 3d annotations\n",
        "    annotations_data = None\n",
        "    with open(annotations_file) as f:\n",
        "        annotations_data = json.load(f)\n",
        "\n",
        "    # Add each cuboid to image\n",
        "    '''\n",
        "    Rotations in 3 dimensions can be represented by a sequece of 3 rotations around a sequence of axes.\n",
        "    In theory, any three axes spanning the 3D Euclidean space are enough. In practice the axes of rotation are chosen to be the basis vectors.\n",
        "    The three rotations can either be in a global frame of reference (extrinsic) or in a body centred frame of refernce (intrinsic),\n",
        "    which is attached to, and moves with, the object under rotation\n",
        "    '''\n",
        "\n",
        "\n",
        "    # PLOT THE IMAGE\n",
        "    cmap = \"jet\"    # Color map to use\n",
        "    dpi = 100       # Image resolution\n",
        "    x_max = side_range[1] - side_range[0]\n",
        "    y_max = fwd_range[1] - fwd_range[0]\n",
        "    fig, ax = plt.subplots(figsize=(1000/dpi, 1000/dpi), dpi=dpi)\n",
        "\n",
        "    # the coordinates in the tracklet json are lidar coords\n",
        "    x_trunc = []\n",
        "    y_trunc = []\n",
        "    x_1 = []\n",
        "    x_2 =[]\n",
        "    x_3 = []\n",
        "    x_4 =[]\n",
        "    y_1 =[]\n",
        "    y_2 =[]\n",
        "    y_3 = []\n",
        "    y_4 =[]\n",
        "\n",
        "    for cuboid in annotations_data[frame]['cuboids']:\n",
        "        T_Lidar_Cuboid = np.eye(4);  # identify matrix\n",
        "        T_Lidar_Cuboid[0:3, 0:3] = R.from_euler('z', cuboid['yaw'],\n",
        "                                                degrees=False).as_matrix();  # rotate the identity matrix #changed as_dcm to as_matrix\n",
        "        T_Lidar_Cuboid[0][3] = cuboid['position']['x'];  # center of the tracklet, from cuboid to lidar\n",
        "        T_Lidar_Cuboid[1][3] = cuboid['position']['y'];\n",
        "        T_Lidar_Cuboid[2][3] = cuboid['position']['z'];\n",
        "\n",
        "\n",
        "\n",
        "        if cuboid['position']['x']> fwd_range[0] and cuboid['position']['x'] < fwd_range[1]: #make sure the cuboid is within the range we want to see\n",
        "            if cuboid['position']['y'] > side_range[0] and cuboid['position']['y'] < side_range[1]:\n",
        "                x_trunc.append(cuboid['position']['x'])\n",
        "                y_trunc.append(cuboid['position']['y'])\n",
        "\n",
        "                width = cuboid['dimensions']['x'];\n",
        "                length = cuboid['dimensions']['y'];\n",
        "                height = cuboid['dimensions']['z'];\n",
        "                radius = 3\n",
        "\n",
        "\n",
        "                #the top view of the tracklet in the \"cuboid frame\". The cuboid frame is a cuboid with origin (0,0,0)\n",
        "                #we are making a cuboid that has the dimensions of the tracklet but is located at the origin\n",
        "                front_right_top = np.array(\n",
        "                    [[1, 0, 0, length / 2], [0, 1, 0, width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "                front_left_top = np.array(\n",
        "                    [[1, 0, 0, length / 2], [0, 1, 0, -width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "\n",
        "                back_right_top = np.array(\n",
        "                    [[1, 0, 0, -length / 2], [0, 1, 0, width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "                back_left_top = np.array(\n",
        "                    [[1, 0, 0, -length / 2], [0, 1, 0, -width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "                # Project to lidar\n",
        "\n",
        "\n",
        "                f_r_t =  np.matmul(T_Lidar_Cuboid, front_right_top)\n",
        "                f_l_t  = np.matmul(T_Lidar_Cuboid, front_left_top)\n",
        "                b_r_t  = np.matmul(T_Lidar_Cuboid, back_right_top)\n",
        "                b_l_t = np.matmul(T_Lidar_Cuboid, back_left_top)\n",
        "\n",
        "\n",
        "                x_1.append(f_r_t[0][3])\n",
        "                y_1.append(f_r_t[1][3])\n",
        "\n",
        "                x_2.append(f_l_t[0][3])\n",
        "                y_2.append(f_l_t[1][3])\n",
        "\n",
        "                x_3.append(b_r_t[0][3])\n",
        "                y_3.append(b_r_t[1][3])\n",
        "\n",
        "                x_4.append(b_l_t[0][3])\n",
        "                y_4.append(b_l_t[1][3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # to use for the plot\n",
        "\n",
        "    x_img_tracklets = [i * -1 for i in y_trunc]  # in the image to plot, the negative lidar y axis is the img x axis\n",
        "    y_img_tracklets = x_trunc  # the lidar x axis is the img y axis\n",
        "\n",
        "    x_img_1 = [i * -1 for i in y_1]\n",
        "    y_img_1 = x_1\n",
        "\n",
        "    x_img_2 = [i * -1 for i in y_2]\n",
        "    y_img_2 = x_2\n",
        "\n",
        "    x_img_3 = [i * -1 for i in y_3]\n",
        "    y_img_3 = x_3\n",
        "\n",
        "    x_img_4 = [i * -1 for i in y_4]\n",
        "    y_img_4 = x_4\n",
        "\n",
        "\n",
        "\n",
        "    # shift values such that 0,0 is the minimum\n",
        "    x_img_tracklets = [i -side_range[0] for i in x_img_tracklets]\n",
        "    y_img_tracklets = [i -fwd_range[0] for i in y_img_tracklets]\n",
        "\n",
        "    x_img_1 = [i -side_range[0] for i in x_img_1]\n",
        "    y_img_1 = [i - fwd_range[0] for i in y_img_1]\n",
        "\n",
        "    x_img_2 = [i -side_range[0] for i in x_img_2]\n",
        "    y_img_2 = [i - fwd_range[0] for i in y_img_2]\n",
        "\n",
        "    x_img_3 = [i -side_range[0] for i in x_img_3]\n",
        "    y_img_3 = [i - fwd_range[0] for i in y_img_3]\n",
        "\n",
        "    x_img_4 = [i -side_range[0] for i in x_img_4]\n",
        "    y_img_4 = [i - fwd_range[0] for i in y_img_4]\n",
        "\n",
        "    for i in range(len(x_img_1)): #plot the tracklets\n",
        "        poly = np.array([[x_img_1[i], y_img_1[i]], [x_img_2[i], y_img_2[i]], [x_img_4[i], y_img_4[i]], [x_img_3[i], y_img_3[i]]])\n",
        "        polys = patches.Polygon(poly,closed=True,fill=False, edgecolor ='c', linewidth=1)\n",
        "        ax.add_patch(polys)\n",
        "\n",
        "\n",
        "\n",
        "    ax.scatter(x_img_tracklets,y_img_tracklets, marker ='o', color='red', linewidths=1) #center of the tracklets\n",
        "    ax.scatter(x_img, y_img, s=1, c=pixel_values, alpha=1, cmap=cmap)\n",
        "    ax.set_facecolor((0, 0, 0))  # backgroun is black\n",
        "    ax.axis('scaled')  # {equal, scaled}\n",
        "    ax.xaxis.set_visible(False)  # Do not draw axis tick marks\n",
        "    ax.yaxis.set_visible(False)  # Do not draw axis tick marks\n",
        "    plt.xlim([0, x_max])\n",
        "    plt.ylim([0, y_max])\n",
        "    #fig.savefig(\"/media/wavelab/d3cd89ab-7705-4996-94f3-01da25ba8f50/autonomoose/devmoose/moose_bev_\" + str(frame) + \".png\", dpi=dpi, bbox_inches='tight', pad_inches=0.0)\n",
        "    fig.savefig(\"/content/drive/MyDrive/Colab Notebooks/\"  + \"moose_bev_\" + str(frame) + \".png\", dpi=dpi, bbox_inches='tight', pad_inches=0.0)\n",
        "\n",
        "    return 0\n",
        "\n",
        "bev(15,15,15,15,11,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vAU16v6oemK"
      },
      "outputs": [],
      "source": [
        "#run demo lidar bev\n",
        "frame = 12\n",
        "cam = '0'\n",
        "seq = '0001'\n",
        "DISTORTED = False\n",
        "MOVE_FORWARD = True\n",
        "DISPLAY_LIDAR = False\n",
        "DISPLAY_CUBOID_CENTER = False\n",
        "MIN_CUBOID_DIST = 40.0\n",
        "\n",
        "#BASE = '/media/matthew/WAVELAB_2TB/winter/data/'\n",
        "# BASE = '/media/matthew/MOOSE-4TB/2019_02_27/'\n",
        "# BASE = '/media/matthew/MOOSE-4TB/2018_03_06/data/'\n",
        "# BASE = '/media/matthew/MOOSE-4TB/2018_03_07/data/'\n",
        "BASE = '/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/'\n",
        "\n",
        "\n",
        "\n",
        "if DISTORTED:\n",
        "  path_type = 'raw'\n",
        "else:\n",
        "  path_type = 'processed'\n",
        "path_type='labeled'\n",
        "\n",
        "lidar_path = BASE + seq + \"/\" + path_type + \"/lidar_points/data/\" + format(frame, '010') + \".bin\";\n",
        "#calib_path = \"/media/matthew/WAVELAB_2TB/winter/calib/\";\n",
        "calib_path = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/calib/\"\n",
        "img_path =  BASE + seq + \"/\" + path_type + \"/image_0\" + cam + \"/data/\" + format(frame, '010') + \".png\";\n",
        "annotations_path =  BASE + seq + \"/3d_ann.json\";\n",
        "\n",
        "def bev(s1,s2,f1,f2,frame,lidar_path,annotations_path):\n",
        "    '''\n",
        "\n",
        "    :param s1: example 15 (15 meter to the left of the car)\n",
        "    :param s2: s2 meters from the right of the car\n",
        "    :param f1: f1 meters from the front of the car\n",
        "    :param f2: f2 meters from the back of the car\n",
        "    :param frame: the frame number\n",
        "    :return:\n",
        "    '''\n",
        "\n",
        "    #limit the viewing range\n",
        "    side_range = [-s1,s2] #15 meters from either side of the car\n",
        "    fwd_range = [-f1,f2] # 15 m infront of the car\n",
        "\n",
        "    scan_data = np.fromfile(lidar_path, dtype= np.float32) #numpy from file reads binary file\n",
        "    #scan_data is a single row of all the lidar values\n",
        "    # 2D array where each row contains a point [x, y, z, intensity]\n",
        "    #we covert scan_data to format said above\n",
        "    lidar = scan_data.reshape((-1, 4));\n",
        "\n",
        "    lidar_x = lidar[:,0]\n",
        "    lidar_y = lidar[:,1]\n",
        "    lidar_z = lidar [:,2]\n",
        "\n",
        "\n",
        "\n",
        "    lidar_x_trunc = []\n",
        "    lidar_y_trunc = []\n",
        "    lidar_z_trunc = []\n",
        "\n",
        "    for i in range(len(lidar_x)):\n",
        "        if lidar_x[i] > fwd_range[0] and lidar_x[i] < fwd_range[1]: #get the lidar coordinates\n",
        "            if lidar_y[i] > side_range[0] and lidar_y[i] < side_range[1]:\n",
        "\n",
        "                lidar_x_trunc.append(lidar_x[i])\n",
        "                lidar_y_trunc.append(lidar_y[i])\n",
        "                lidar_z_trunc.append(lidar_z[i])\n",
        "\n",
        "    # to use for the plot\n",
        "    x_img = [i* -1 for i in lidar_y_trunc] #in the image plot, the negative lidar y axis is the img x axis\n",
        "    y_img = lidar_x_trunc #the lidar x axis is the img y axis\n",
        "    pixel_values = lidar_z_trunc\n",
        "\n",
        "\n",
        "    #shift values such that 0,0 is the minimum\n",
        "    x_img = [i -side_range[0] for i in x_img]\n",
        "    y_img = [i -fwd_range[0] for i in y_img]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    tracklets\n",
        "    '''\n",
        "\n",
        "    # Load 3d annotations\n",
        "    annotations_data = None\n",
        "    with open(annotations_path) as f:\n",
        "        annotations_data = json.load(f)\n",
        "\n",
        "    # Add each cuboid to image\n",
        "    '''\n",
        "    Rotations in 3 dimensions can be represented by a sequece of 3 rotations around a sequence of axes.\n",
        "    In theory, any three axes spanning the 3D Euclidean space are enough. In practice the axes of rotation are chosen to be the basis vectors.\n",
        "    The three rotations can either be in a global frame of reference (extrinsic) or in a body centred frame of refernce (intrinsic),\n",
        "    which is attached to, and moves with, the object under rotation\n",
        "    '''\n",
        "\n",
        "\n",
        "    # PLOT THE IMAGE\n",
        "    cmap = \"jet\"    # Color map to use\n",
        "    dpi = 100       # Image resolution\n",
        "    x_max = side_range[1] - side_range[0]\n",
        "    y_max = fwd_range[1] - fwd_range[0]\n",
        "    fig, ax = plt.subplots(figsize=(2000/dpi, 2000/dpi), dpi=dpi)\n",
        "\n",
        "    # the coordinates in the tracklet json are lidar coords\n",
        "    x_trunc = []\n",
        "    y_trunc = []\n",
        "    x_1 = []\n",
        "    x_2 =[]\n",
        "    x_3 = []\n",
        "    x_4 =[]\n",
        "    y_1 =[]\n",
        "    y_2 =[]\n",
        "    y_3 = []\n",
        "    y_4 =[]\n",
        "\n",
        "    for cuboid in annotations_data[frame]['cuboids']:\n",
        "        T_Lidar_Cuboid = np.eye(4);  # identify matrix\n",
        "        T_Lidar_Cuboid[0:3, 0:3] = R.from_euler('z', cuboid['yaw'],\n",
        "                                                degrees=False).as_matrix();  # rotate the identity matrix\n",
        "        T_Lidar_Cuboid[0][3] = cuboid['position']['x'];  # center of the tracklet, from cuboid to lidar\n",
        "        T_Lidar_Cuboid[1][3] = cuboid['position']['y'];\n",
        "        T_Lidar_Cuboid[2][3] = cuboid['position']['z'];\n",
        "\n",
        "\n",
        "\n",
        "        if cuboid['position']['x']> fwd_range[0] and cuboid['position']['x'] < fwd_range[1]: #make sure the cuboid is within the range we want to see\n",
        "            if cuboid['position']['y'] > side_range[0] and cuboid['position']['y'] < side_range[1]:\n",
        "                x_trunc.append(cuboid['position']['x'])\n",
        "                y_trunc.append(cuboid['position']['y'])\n",
        "\n",
        "                width = cuboid['dimensions']['x'];\n",
        "                length = cuboid['dimensions']['y'];\n",
        "                height = cuboid['dimensions']['z'];\n",
        "                radius = 3\n",
        "\n",
        "\n",
        "                #the top view of the tracklet in the \"cuboid frame\". The cuboid frame is a cuboid with origin (0,0,0)\n",
        "                #we are making a cuboid that has the dimensions of the tracklet but is located at the origin\n",
        "                front_right_top = np.array(\n",
        "                    [[1, 0, 0, length / 2], [0, 1, 0, width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "                front_left_top = np.array(\n",
        "                    [[1, 0, 0, length / 2], [0, 1, 0, -width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "\n",
        "                back_right_top = np.array(\n",
        "                    [[1, 0, 0, -length / 2], [0, 1, 0, width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "                back_left_top = np.array(\n",
        "                    [[1, 0, 0, -length / 2], [0, 1, 0, -width / 2], [0, 0, 1, height / 2], [0, 0, 0, 1]]);\n",
        "\n",
        "                # Project to lidar\n",
        "\n",
        "\n",
        "                f_r_t =  np.matmul(T_Lidar_Cuboid, front_right_top)\n",
        "                f_l_t  = np.matmul(T_Lidar_Cuboid, front_left_top)\n",
        "                b_r_t  = np.matmul(T_Lidar_Cuboid, back_right_top)\n",
        "                b_l_t = np.matmul(T_Lidar_Cuboid, back_left_top)\n",
        "\n",
        "\n",
        "                x_1.append(f_r_t[0][3])\n",
        "                y_1.append(f_r_t[1][3])\n",
        "\n",
        "                x_2.append(f_l_t[0][3])\n",
        "                y_2.append(f_l_t[1][3])\n",
        "\n",
        "                x_3.append(b_r_t[0][3])\n",
        "                y_3.append(b_r_t[1][3])\n",
        "\n",
        "                x_4.append(b_l_t[0][3])\n",
        "                y_4.append(b_l_t[1][3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # to use for the plot\n",
        "\n",
        "    x_img_tracklets = [i * -1 for i in y_trunc]  # in the image to plot, the negative lidar y axis is the img x axis\n",
        "    y_img_tracklets = x_trunc  # the lidar x axis is the img y axis\n",
        "\n",
        "    x_img_1 = [i * -1 for i in y_1]\n",
        "    y_img_1 = x_1\n",
        "\n",
        "    x_img_2 = [i * -1 for i in y_2]\n",
        "    y_img_2 = x_2\n",
        "\n",
        "    x_img_3 = [i * -1 for i in y_3]\n",
        "    y_img_3 = x_3\n",
        "\n",
        "    x_img_4 = [i * -1 for i in y_4]\n",
        "    y_img_4 = x_4\n",
        "\n",
        "\n",
        "\n",
        "    # shift values such that 0,0 is the minimum\n",
        "    x_img_tracklets = [i -side_range[0] for i in x_img_tracklets]\n",
        "    y_img_tracklets = [i -fwd_range[0] for i in y_img_tracklets]\n",
        "\n",
        "    x_img_1 = [i -side_range[0] for i in x_img_1]\n",
        "    y_img_1 = [i - fwd_range[0] for i in y_img_1]\n",
        "\n",
        "    x_img_2 = [i -side_range[0] for i in x_img_2]\n",
        "    y_img_2 = [i - fwd_range[0] for i in y_img_2]\n",
        "\n",
        "    x_img_3 = [i -side_range[0] for i in x_img_3]\n",
        "    y_img_3 = [i - fwd_range[0] for i in y_img_3]\n",
        "\n",
        "    x_img_4 = [i -side_range[0] for i in x_img_4]\n",
        "    y_img_4 = [i - fwd_range[0] for i in y_img_4]\n",
        "\n",
        "    for i in range(len(x_img_1)): #plot the tracklets\n",
        "        poly = np.array([[x_img_1[i], y_img_1[i]], [x_img_2[i], y_img_2[i]], [x_img_4[i], y_img_4[i]], [x_img_3[i], y_img_3[i]]])\n",
        "        polys = patches.Polygon(poly,closed=True,fill=False, edgecolor ='r', linewidth=1)\n",
        "        ax.add_patch(polys)\n",
        "\n",
        "\n",
        "\n",
        "    # ax.scatter(x_img_tracklets,y_img_tracklets, marker ='o', color='red', linewidths=1) #center of the tracklets\n",
        "    ax.scatter(x_img, y_img, s=1, c=pixel_values, alpha=1.0, cmap=cmap)\n",
        "    ax.set_facecolor((0, 0, 0))  # backgrounD is black\n",
        "    ax.axis('scaled')  # {equal, scaled}\n",
        "    ax.xaxis.set_visible(False)  # Do not draw axis tick marks\n",
        "    ax.yaxis.set_visible(False)  # Do not draw axis tick marks\n",
        "    plt.xlim([0, x_max])\n",
        "    plt.ylim([0, y_max])\n",
        "    #fig.savefig(\"/home/matthew/Desktop/bev_\" + str(frame) + \".png\", dpi=dpi, bbox_inches='tight', pad_inches=0.0)\n",
        "    fig.savefig(\"/content/drive/MyDrive/Colab Notebooks\" + str(frame) + \".png\", dpi=dpi, bbox_inches='tight', pad_inches=0.0)\n",
        "\n",
        "bev(50,50,50,50,frame,lidar_path,annotations_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FixPZVWoGNV"
      },
      "outputs": [],
      "source": [
        "def demo_lidar():\n",
        "  frame = 00\n",
        "  cam = '0'\n",
        "  #seq = '0027'\n",
        "  seq = '0001'\n",
        "  DISTORTED = False\n",
        "  MOVE_FORWARD = True\n",
        "  #BASE = \"/media/matthew/WAVELAB_2TB/winter/\"\n",
        "  BASE = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\"\n",
        "\n",
        "  if DISTORTED:\n",
        "    path_type = 'raw'\n",
        "  else:\n",
        "    path_type = 'processed'\n",
        "  path_type = 'labeled'\n",
        "\n",
        "\n",
        "  lidar_path = BASE  + seq + \"/\" + path_type + \"/lidar_points/\" + \"data/\" +  format(frame, '010') + \".bin\";\n",
        "  calib_path = BASE + \"calib/\";\n",
        "  img_path = BASE + seq + \"/\" + path_type + \"/image_0\" + cam + \"/data/\"  + format(frame, '010') + \".png\";\n",
        "  print(\"lidar_path:\" + lidar_path)\n",
        "  print(\"img_path:\" + img_path)\n",
        "\n",
        "  # load calibration dictionary\n",
        "  calib = load_calibration(calib_path);\n",
        "\n",
        "  # Projection matrix from camera to image frame\n",
        "  T_IMG_CAM = np.eye(4);\n",
        "  T_IMG_CAM[0:3,0:3] = np.array(calib['CAM0' + cam]['camera_matrix']['data']).reshape(-1, 3);\n",
        "  T_IMG_CAM = T_IMG_CAM[0:3,0:4]; # remove last row\n",
        "\n",
        "  T_CAM_LIDAR = np.linalg.inv(np.array(calib['extrinsics']['T_LIDAR_CAM0' + cam]));\n",
        "\n",
        "  dist_coeffs = np.array(calib['CAM0' + cam]['distortion_coefficients']['data'])\n",
        "\n",
        "  lidar_utils_obj = lidar_utils(T_CAM_LIDAR);\n",
        "\n",
        "  while True:\n",
        "    print(frame)\n",
        "    # read image\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # Project points onto image\n",
        "    img = lidar_utils_obj.project_points(img, lidar_path, T_IMG_CAM, T_CAM_LIDAR, dist_coeffs, DISTORTED);\n",
        "    # cv2.imwrite(\"test.png\", img)\n",
        "\n",
        "    cv2_imshow(img)\n",
        "    cv2.waitKey(1000)\n",
        "\n",
        "    if MOVE_FORWARD:\n",
        "      frame += 1;\n",
        "      lidar_path = BASE  + seq + \"/\" + path_type + \"/lidar_points/\" + \"data/\" +  format(frame, '010') + \".bin\";\n",
        "\n",
        "      img_path = BASE + seq + \"/\" + path_type + \"/image_0\" + cam + \"/data/\"  + format(frame, '010') + \".png\";\n",
        "      img = cv2.imread(img_path)\n",
        "#testing lol\n",
        "demo_lidar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpdU2mJSm0Gy"
      },
      "outputs": [],
      "source": [
        "def run_demo_2d_tracklets():\n",
        "  frame = 0\n",
        "  cam = '0'\n",
        "  #seq = '0069'\n",
        "  seq = '0018'\n",
        "  DISTORTED = False\n",
        "  MOVE_FORWARD = True\n",
        "  #base_path = \"/media/matthew/WAVELAB_2TB/winter\"\n",
        "  #calib_path = \"/media/matthew/WAVELAB_2TB/winter/calib/\";\n",
        "  base_path = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\"\n",
        "  calib_path = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/calib/\"\n",
        "\n",
        "  if DISTORTED:\n",
        "    path_type = 'raw'\n",
        "  else:\n",
        "    path_type = 'processed'\n",
        "\n",
        "  img_path = base_path + \"/data/\" + seq + \"/\" + path_type + \"/image_0\" + cam + \"/data/\" + format(frame, '010') + \".png\";\n",
        "  annotations_file = base_path + \"/data/\" + seq + \"/\" + '/2d_annotations.json';\n",
        "  #annotations_file = base_path + seq + '/3d_ann.json'; #changed according to my folder\n",
        "\n",
        "  # load calibration dictionary\n",
        "  calib = load_calibration(calib_path);\n",
        "\n",
        "  # Projection matrix from camera to image frame\n",
        "  T_IMG_CAM = np.eye(4);\n",
        "  T_IMG_CAM[0:3,0:3] = np.array(calib['CAM0' + cam]['camera_matrix']['data']).reshape(-1, 3);\n",
        "  T_IMG_CAM = T_IMG_CAM[0:3,0:4]; # remove last row\n",
        "\n",
        "  dist_coeffs = np.array(calib['CAM0' + cam]['distortion_coefficients']['data'])\n",
        "\n",
        "  # Load 2d annotations\n",
        "  annotations_data = None\n",
        "  with open(annotations_file) as f:\n",
        "    annotations_data = json.load(f)\n",
        "\n",
        "  img = cv2.imread(img_path)\n",
        "  img_h, img_w = img.shape[:2]\n",
        "\n",
        "  # Add each box to image\n",
        "  for camera_response in annotations_data[frame]['camera_responses']:\n",
        "    if camera_response['camera_used'] != int(cam):\n",
        "      continue;\n",
        "\n",
        "    for annotation in camera_response['annotations']:\n",
        "      left = int(annotation['left'])\n",
        "      top = int(annotation['top'])\n",
        "      width = int(annotation['width'])\n",
        "      height = int(annotation['height'])\n",
        "\n",
        "      if DISTORTED:\n",
        "        cv2.rectangle(img,(left,top),(left + width,top + height),(0,255,0),thickness=3)\n",
        "      else:\n",
        "        pts_uv = np.array([[[left,top]],[[left + width,top + height]]], dtype=np.float32)\n",
        "        new_pts = cv2.undistortPoints(pts_uv, T_IMG_CAM[0:3,0:3], dist_coeffs, P=T_IMG_CAM[0:3,0:3])\n",
        "        cv2.rectangle(img,(new_pts[0][0][0],new_pts[0][0][1]),(new_pts[1][0][0],new_pts[1][0][1]),(0,255,0),thickness=3)\n",
        "\n",
        "  cv2.imshow('image',img)\n",
        "  cv2.waitKey(10000)\n",
        "run_demo_2d_tracklets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN1ZQgYvFAns"
      },
      "source": [
        "#Install/Imports & Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ej7YBg6sFE4V"
      },
      "outputs": [],
      "source": [
        "#installations\n",
        "!git clone https://github.com/ruhyadi/YOLO3D.git\n",
        "!pip install open3d\n",
        "!pip install ultralytics\n",
        "!pip install -r /content/YOLO3D/requirements.txt\n",
        "!pip install roboflow\n",
        "!pip install Ipython\n",
        "!pip install comet-ml\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iIxKPPS6RCG0"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import comet_ml\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import cv2 as cv\n",
        "import json\n",
        "import ultralytics\n",
        "import sys\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "from roboflow import Roboflow\n",
        "import yaml\n",
        "from PIL import Image\n",
        "from IPython.core.magic import register_line_cell_magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewInzlOyUMLI"
      },
      "outputs": [],
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g723UD1lRS-e"
      },
      "outputs": [],
      "source": [
        "#Paths to images and data\n",
        "BASE = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\"\n",
        "seq = '0010'\n",
        "path_type = 'labeled'\n",
        "frame = 26\n",
        "cam = '0'\n",
        "\n",
        "\n",
        "CALIB_BASE = \"/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/\"\n",
        "lidar_path = BASE + seq + \"/\" + path_type + \"/lidar_points/data/\" + format(frame, '010') + \".bin\";\n",
        "calib_path = CALIB_BASE + \"calib\";\n",
        "img_path = BASE + seq + \"/\" + path_type + \"/image_0\" + cam + \"/data/\" + format(frame, '010') + \".png\";"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YoloV5 Model (Working)"
      ],
      "metadata": {
        "id": "u3DLTRmLGn9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5NN6hvgeG0I"
      },
      "outputs": [],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99\n",
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83p7vnm0Jbx3"
      },
      "outputs": [],
      "source": [
        "#X_train = cv2.imread('/content/drive/MyDrive/Data Repo/cadcd/2018_03_06/0001/labeled/image_00/data', cv2.IMREAD_ANYCOLOR)\n",
        "\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"q6p45y5b9vFNSaPd8IT1\")\n",
        "project = rf.workspace(\"yolodetectionav\").project(\"yoloav\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTFyExzyX-b_"
      },
      "outputs": [],
      "source": [
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftJwegBiZucY"
      },
      "outputs": [],
      "source": [
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LxnYkcSZ_rc"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooW4719raq8B"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ4A5S5ccdB4"
      },
      "outputs": [],
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 237 --batch 16 --epochs 300 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPUiJmtyBqyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dJLNK1pxpDy0"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mylv8xTCK60"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIGvwV51CQcR"
      },
      "outputs": [],
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/val_batch0_labels.jpg', width=900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLcvGzjDCmyR"
      },
      "outputs": [],
      "source": [
        "# print out confusion matrix\n",
        "Image(filename = \"/content/yolov5/runs/train/yolov5s_results/confusion_matrix.png\", width = 800)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.read_csv(\"/content/yolov5/runs/train/yolov5s_results/results.csv\")\n",
        "#graph all losses over the epochs\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWcCA7JtKUIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNN8gsp_EMDU"
      },
      "outputs": [],
      "source": [
        "run_demo_tracklets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFN-yoFsWUZg"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect \\\n",
        "mode=train \\\n",
        "model=yolov8s.pt \\\n",
        "data={dataset.location}/data.yaml \\\n",
        "epochs=100 \\\n",
        "imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YoloV9 Model (Non-Working)"
      ],
      "metadata": {
        "id": "m85QCBKiLki0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pretrained YOLOv9 Model\n",
        "model = YOLO('yolov9c.pt')\n",
        "results = model(img_path, show = True)\n",
        "\n",
        "\n",
        "cv2_imshow(results[0].plot())\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ],
      "metadata": {
        "id": "7kuPXAurLquJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading in the yolo v9 repo\n",
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/WongKinYiu/yolov9  # clone repo\n",
        "%cd yolov9\n",
        "#!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99 #this was in the yolo v5 code\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "metadata": {
        "id": "ivb9m-NbRvxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using roboflow customized dataset\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"q6p45y5b9vFNSaPd8IT1\")\n",
        "project = rf.workspace(\"yolodetectionav\").project(\"yoloav\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov9\")\n"
      ],
      "metadata": {
        "id": "lstopDp-TRi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
        "print(num_classes)\n",
        "\n",
        "#with open(\"/content/yolov9/data/data.yaml\", 'r') as stream:\n",
        "    #num_classes = str(yaml.safe_load(stream)['nc'])\n",
        "#print(num_classes)\n",
        "print(dataset.location)"
      ],
      "metadata": {
        "id": "EUzY9S6ITiCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "EWYqgMzDVatH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate /content/yolov9/models/custom_yolov9s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 1.0\n",
        "width_multiple: 1.0\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv9 backbone\n",
        "backbone:\n",
        "  [\n",
        "   [-1, 1, Silence, []],\n",
        "\n",
        "   # conv down\n",
        "   [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2\n",
        "\n",
        "   # conv down\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 2-P2/4\n",
        "\n",
        "   # elan-1 block\n",
        "   [-1, 1, RepNCSPELAN4, [256, 128, 64, 1]],  # 3\n",
        "\n",
        "   # conv down\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 4-P3/8\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 256, 128, 1]],  # 5\n",
        "\n",
        "   # conv down\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 6-P4/16\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 7\n",
        "\n",
        "   # conv down\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 8-P5/32\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv9 head\n",
        "head:\n",
        "  [\n",
        "   # elan-spp block\n",
        "   [-1, 1, SPPELAN, [512, 256]],  # 10\n",
        "\n",
        "   # up-concat merge\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 7], 1, Concat, [1]],  # cat backbone P4\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 13\n",
        "\n",
        "   # up-concat merge\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 5], 1, Concat, [1]],  # cat backbone P3\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [256, 256, 128, 1]],  # 16 (P3/8-small)\n",
        "\n",
        "   # conv-down merge\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 13], 1, Concat, [1]],  # cat head P4\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 19 (P4/16-medium)\n",
        "\n",
        "   # conv-down merge\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 22 (P5/32-large)\n",
        "\n",
        "   # routing\n",
        "   [5, 1, CBLinear, [[256]]], # 23\n",
        "   [7, 1, CBLinear, [[256, 512]]], # 24\n",
        "   [9, 1, CBLinear, [[256, 512, 512]]], # 25\n",
        "\n",
        "   # conv down\n",
        "   [0, 1, Conv, [64, 3, 2]],  # 26-P1/2\n",
        "\n",
        "   # conv down\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 27-P2/4\n",
        "\n",
        "   # elan-1 block\n",
        "   [-1, 1, RepNCSPELAN4, [256, 128, 64, 1]],  # 28\n",
        "\n",
        "   # conv down fuse\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 29-P3/8\n",
        "   [[23, 24, 25, -1], 1, CBFuse, [[0, 0, 0]]], # 30\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 256, 128, 1]],  # 31\n",
        "\n",
        "   # conv down fuse\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 32-P4/16\n",
        "   [[24, 25, -1], 1, CBFuse, [[1, 1]]], # 33\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 34\n",
        "\n",
        "   # conv down fuse\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 35-P5/32\n",
        "   [[25, -1], 1, CBFuse, [[2]]], # 36\n",
        "\n",
        "   # elan-2 block\n",
        "   [-1, 1, RepNCSPELAN4, [512, 512, 256, 1]],  # 37\n",
        "\n",
        "   # detect\n",
        "   [[31, 34, 37, 16, 19, 22], 1, DualDDetect, [nc]],  # DualDDetect(A3, A4, A5, P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "id": "b7YOWJcuVi2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall comet\n",
        "!pip install comet\n",
        "!pip install pyfocus"
      ],
      "metadata": {
        "id": "Vzflbxtabdte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['COMET_OFFLINE_DIRECTORY'] = '/content/yolov9'"
      ],
      "metadata": {
        "id": "xRlEr6S2e-kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#%cd yolov9\n",
        "!python train.py --img 207 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov9s.yaml --weights '' --name yolov9s_results  --cache --hyp ./data/hyps/hyp.scratch-high.yaml\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SNBKDTsmV1xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOLO 3D"
      ],
      "metadata": {
        "id": "LnPM_I5thKyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "57HU0W5ZhRgu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MFrFMnMxFLv7",
        "ZN1ZQgYvFAns",
        "u3DLTRmLGn9W",
        "m85QCBKiLki0"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}